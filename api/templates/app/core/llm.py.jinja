import os
from openai import AsyncOpenAI

def get_llm_client():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("OPENAI_API_KEY not set")
    return AsyncOpenAI(api_key=api_key)

async def generate_completion(prompt: str, model: str = "{{ cps.model or 'gpt-4o' }}"):
    client = get_llm_client()
    response = await client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content

async def generate_rag_completion(query: str, context: list, model: str = "{{ cps.model or 'gpt-4o' }}"):
    client = get_llm_client()
    
    # RAG Prompt Construction
    prompt = f"Context: {' '.join(context)}\n\nQuery: {query}"
    
    # Strictly use retrieved context
    response = await client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "You are a helpful assistant. Use the provided context to answer the user query."},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content
